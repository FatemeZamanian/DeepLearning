{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flowers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYmSgV+I69zLjsM3dw7yO2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatemeZamanian/DeepLearning/blob/main/Flowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVtuBvHWSuR0",
        "outputId": "aceb8a77-d2a8-49db-a05e-db3113f7aa4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21024cvgS52Y"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhqIFHwXTnC8"
      },
      "source": [
        "dataset_path=\"/content/drive/MyDrive/Flowers\"\n",
        "width=height=224\n",
        "batch_size=32\n",
        "data_generator=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    validation_split=0.1\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kBpBcORXBx5",
        "outputId": "86907bde-9e4b-4a80-fbe0-d114b70b0168"
      },
      "source": [
        "train_data=data_generator.flow_from_directory(\n",
        "    os.path.join(dataset_path,'Train'),\n",
        "    target_size=(width,height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    subset='training',\n",
        "\n",
        ")\n",
        "\n",
        "val_data=data_generator.flow_from_directory(\n",
        "    os.path.join(dataset_path,'Train'),\n",
        "    target_size=(width,height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    subset='validation',\n",
        "\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 986 images belonging to 17 classes.\n",
            "Found 102 images belonging to 17 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKdi9WoMZjGQ"
      },
      "source": [
        "model_v=tf.keras.applications.VGG16(\n",
        "    input_shape=(width,height,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFsnryCJiLCg"
      },
      "source": [
        "for layer in model_v.layers:\n",
        "  layer.trainable=False"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1E9jxTfPR-Q"
      },
      "source": [
        "model=tf.keras.Sequential([\n",
        "        model_v,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1024,activation='relu'),\n",
        "        layers.Dense(128,activation='relu'),\n",
        "        layers.Dense(17,activation='softmax'),\n",
        "])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI7VkmZaS1g6"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDxtUZR7TInH"
      },
      "source": [
        "wandb.init(project=\"Flowers\")\n",
        "config = wandb.config\n",
        "config.learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EsUhKv_aiN2"
      },
      "source": [
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= config.learning_rate ),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'],)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYcj06r7L3yg",
        "outputId": "7f4b3a85-428a-4699-b0cd-a901db234f7f"
      },
      "source": [
        "model.fit(train_data,\n",
        "          steps_per_epoch=train_data.samples//batch_size,\n",
        "          validation_data=val_data,\n",
        "          validation_steps=val_data.samples/batch_size,\n",
        "          epochs=10,\n",
        "          callbacks=[WandbCallback()]\n",
        "\n",
        "    \n",
        ")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 24s 757ms/step - loss: 3.6342 - accuracy: 0.3124 - val_loss: 1.2880 - val_accuracy: 0.6078\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 22s 729ms/step - loss: 0.9026 - accuracy: 0.7306 - val_loss: 0.6655 - val_accuracy: 0.7941\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 22s 730ms/step - loss: 0.4567 - accuracy: 0.8753 - val_loss: 0.5619 - val_accuracy: 0.8039\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 22s 729ms/step - loss: 0.3022 - accuracy: 0.9208 - val_loss: 0.3136 - val_accuracy: 0.8922\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 22s 728ms/step - loss: 0.1464 - accuracy: 0.9748 - val_loss: 0.4216 - val_accuracy: 0.8431\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 22s 726ms/step - loss: 0.1195 - accuracy: 0.9811 - val_loss: 0.2792 - val_accuracy: 0.8922\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 22s 726ms/step - loss: 0.1042 - accuracy: 0.9832 - val_loss: 0.3416 - val_accuracy: 0.8922\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 22s 724ms/step - loss: 0.0764 - accuracy: 0.9885 - val_loss: 0.3351 - val_accuracy: 0.8824\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 22s 724ms/step - loss: 0.0467 - accuracy: 0.9969 - val_loss: 0.2324 - val_accuracy: 0.9216\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 22s 726ms/step - loss: 0.0269 - accuracy: 0.9979 - val_loss: 0.2334 - val_accuracy: 0.9314\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0db3603610>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}