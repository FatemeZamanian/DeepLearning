{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenderRecognisionTrain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MbA_iqGRTWEktuSbP51xjI8JjFR4ZgCr",
      "authorship_tag": "ABX9TyOZs+fLurGfoMEFyNuWMsW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FatemeZamanian/DeepLearning/blob/main/GenderRecognition/GenderRecognisionTrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDM6zOIb9Qkv"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE0qAQi9ZBMp"
      },
      "source": [
        "!kaggle datasets download -d ashishjangra27/gender-recognition-200k-images-celeba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ET0edkXaw3e"
      },
      "source": [
        "!unzip -qq gender-recognition-200k-images-celeba.zip"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuLrYZL-cdgU"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras import models,layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qDPm42K4VDn"
      },
      "source": [
        "width=height=224\n",
        "batch_size=32"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiohg_BCd8u_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f67105dc-9589-440c-da49-8a9c0b880f6a"
      },
      "source": [
        "data_generator=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "train_data=data_generator.flow_from_directory(\n",
        "    \"Dataset/Train\",\n",
        "    target_size=(width,height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "val_data=data_generator.flow_from_directory(\n",
        "    \"Dataset/Validation\",\n",
        "    target_size=(width,height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "test_data=data_generator.flow_from_directory(\n",
        "    \"Dataset/Test\",\n",
        "    target_size=(width,height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160000 images belonging to 2 classes.\n",
            "Found 22598 images belonging to 2 classes.\n",
            "Found 20001 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaSmsFHS5IKE",
        "outputId": "7d6bf9ad-6c14-4d91-c423-6fe7b02f009d"
      },
      "source": [
        "model_r=tf.keras.applications.ResNet50V2(\n",
        "    input_shape=(width,height,3),\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='max'\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 2s 0us/step\n",
            "94683136/94668760 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRG8QbRp5zzV"
      },
      "source": [
        "for layer in model_r.layers[:-2]:\n",
        "  layer.trainable=False"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlLqyqoj6E4O"
      },
      "source": [
        "model=tf.keras.Sequential([\n",
        "        model_r,\n",
        "        layers.Dense(2,activation='softmax'),\n",
        "])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRQDq3JH6RJT"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgG6_cZc6maP"
      },
      "source": [
        "wandb.init(project=\"GenderDetection\")\n",
        "config = wandb.config\n",
        "config.learning_rate = 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gfW-PFJ6tsA"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate= config.learning_rate ),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'],)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBC2oYZq6yRd",
        "outputId": "03dfdac7-aaca-4fdb-cc20-0ccb2b708f59"
      },
      "source": [
        "model.fit(train_data,\n",
        "          steps_per_epoch=train_data.samples/batch_size,\n",
        "          validation_data=val_data,\n",
        "          validation_steps=val_data.samples/batch_size,\n",
        "          epochs=10,\n",
        "          callbacks=[WandbCallback()],\n",
        "\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "5000/5000 [==============================] - 1107s 215ms/step - loss: 0.4189 - accuracy: 0.9148 - val_loss: 0.3799 - val_accuracy: 0.9224\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10\n",
            "5000/5000 [==============================] - 1068s 214ms/step - loss: 0.3799 - accuracy: 0.9232 - val_loss: 0.3489 - val_accuracy: 0.9322\n",
            "Epoch 3/10\n",
            "5000/5000 [==============================] - 1065s 213ms/step - loss: 0.3703 - accuracy: 0.9264 - val_loss: 0.3900 - val_accuracy: 0.9259\n",
            "Epoch 4/10\n",
            "5000/5000 [==============================] - 1064s 213ms/step - loss: 0.3894 - accuracy: 0.9264 - val_loss: 0.3389 - val_accuracy: 0.9364\n",
            "Epoch 5/10\n",
            "5000/5000 [==============================] - 1065s 213ms/step - loss: 0.3810 - accuracy: 0.9273 - val_loss: 0.5158 - val_accuracy: 0.9106\n",
            "Epoch 6/10\n",
            "5000/5000 [==============================] - 1064s 213ms/step - loss: 0.3898 - accuracy: 0.9271 - val_loss: 0.3252 - val_accuracy: 0.9360\n",
            "Epoch 7/10\n",
            "5000/5000 [==============================] - 1075s 215ms/step - loss: 0.3862 - accuracy: 0.9270 - val_loss: 0.4589 - val_accuracy: 0.9162\n",
            "Epoch 8/10\n",
            "5000/5000 [==============================] - 1067s 213ms/step - loss: 0.3852 - accuracy: 0.9274 - val_loss: 0.3161 - val_accuracy: 0.9391\n",
            "Epoch 9/10\n",
            "5000/5000 [==============================] - 1073s 215ms/step - loss: 0.3886 - accuracy: 0.9287 - val_loss: 0.4492 - val_accuracy: 0.9169\n",
            "Epoch 10/10\n",
            "5000/5000 [==============================] - 1085s 217ms/step - loss: 0.3823 - accuracy: 0.9277 - val_loss: 0.3739 - val_accuracy: 0.9294\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb8cbcd8f50>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snvVCPyykYCE",
        "outputId": "fb49dfbb-2c8c-4521-889a-63a316fc0d8d"
      },
      "source": [
        "model.save('gender.h5')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0iTsOQCDXdT",
        "outputId": "0fcbff58-6d92-4b96-8cea-db94854ff992"
      },
      "source": [
        "model.evaluate(test_data)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "626/626 [==============================] - 120s 192ms/step - loss: 0.3140 - accuracy: 0.9364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3139840066432953, 0.9364031553268433]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u7A7tSNW5dP",
        "outputId": "5eb7cf13-8d45-4b3b-b7c3-bdc3637a15fe"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "Y_pred = model.predict(test_data)\n",
        "y_pred = np.argmax(Y_pred, axis = 1)\n",
        "print('confusion Matrix')\n",
        "print(confusion_matrix(test_data.classes, y_pred))\n",
        "\n",
        "target_names = list(test_data.class_indices.keys())\n",
        "print('Classification Report')\n",
        "print(classification_report(test_data.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion Matrix\n",
            "[[11189   353]\n",
            " [  956  7503]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Female       0.92      0.97      0.94     11542\n",
            "        Male       0.96      0.89      0.92      8459\n",
            "\n",
            "    accuracy                           0.93     20001\n",
            "   macro avg       0.94      0.93      0.93     20001\n",
            "weighted avg       0.94      0.93      0.93     20001\n",
            "\n"
          ]
        }
      ]
    }
  ]
}